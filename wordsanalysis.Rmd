---
title: "MA615 Assignment4"
subtitle: "Text Analysis of Pierre and Jean Task Two"
author: "Yuyang Li"
date: "2021/12/6"
output:
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=F,message = F,echo=F,highlight=F)

library(devtools)
library(rticles)
# Set tnum database and source function
library(tnum)
tnum.authorize("mssp1.bu.edu")
tnum.setSpace("test2")
source("Book2TN-v6A-1.R")
```


```{r, echo=FALSE}

#devtools::install_github("Truenumbers/tnum/tnum",force = TRUE)
#install.packages("textdata")
knitr::opts_chunk$set(fig.width=6, fig.height=4,fig.align = "center") 
pacman::p_load(
  gutenbergr,
  tidytext,
  magrittr,
  textdata,
  dplyr,
  stringr,
  tidyverse,
  tidyr,
  scales,
  reshape2,
  ggplot2,
  tinytex,
  latexpdf,
  sentimentr)

```


## Task one : Pick one book

The book I selected called Old Fox Granny written by Thornton W. Burgess from Gutenburg. It's a fairy tale.
```{r, echo=FALSE}
data<- gutenberg_download(4980)
```

## Task two : Words analysis
Firstly I cleaned the data into tidy format and tokenized it, and imported three methods to analysis the sentiment of text.
```{r, include=FALSE}
#data clean
tidy_data <- data %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

tidy_data %>%
  count(word, sort = TRUE)
```

```{r include=FALSE}
#Import three lexicons to analyse sentiment
get_sentiments("afinn")
get_sentiments("nrc")
get_sentiments("bing")
```

```{r include=FALSE}
#This chunk using the sentiment is "joy" from NRC lexicon and get the matching words in my book
nyc_joy <- get_sentiments("nrc")%>%
  filter(sentiment == "joy")

tidy_data %>%
  inner_join(nyc_joy)%>%
  count(word, sort = TRUE)
```

```{r, include=FALSE}
#Creating tidy book, using linenumber to get row number, and getting chapter number.
tidy_book<-data%>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, 
                                regex("^chapter [\\divxlc]", 
                                      ignore_case = TRUE)))) %>%
  ungroup() %>%
  unnest_tokens(word, text)
```

```{r}
# Using BIN lexicon to get sentiment score which is positive minus negative
book_sentiment<-  tidy_book%>%
  inner_join(get_sentiments("bing"))%>%
  count(index = linenumber %/% 80, sentiment)%>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
  mutate(sentiment= positive - negative)
```

Figure 1 shows box plot of sentiment using BING lexicon, and figure 2 shows analysis with three sentiment lexicons. I found that using BING lexicon fits best among these figures. And the main sentiment of whole book tend to be positive.
```{r fig.cap="sentiment plot using bing"}
ggplot(book_sentiment, aes(index, sentiment)) +
  geom_col(show.legend = FALSE, color = "blue")
```

```{r, echo=FALSE}
# Using AFINN lexicon to get sentiment score
afinn <- tidy_book %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")

# Using BING and NRC lexicons to get sentiment score
bing_and_nrc <- bind_rows(
  tidy_book %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  tidy_book %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
```

```{r fig.cap="sentiment plot"}
# Combining three lexicons to plot
bind_rows(afinn, 
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE,width = 0.5) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

Figure 3 shows the number of positive and negative words appeared in book. It's clear that the frequency of positive words is higher than negative. The highest contribution word in positive group is "right" and it's "foolish" in negative group. As we know that this book is a fairy tale, and the main content of the book is when a deep winter snow carpets the Green Forest and nearby meadow, Granny Fox and Reddy have some disagreements on how best to find some food. But Granny -- with her years of experience -- wins out over Reddy and teaches him quite a bit about patience, common sense, and resourcefulness. So the the whole sentiment of book should be positive and relaxing.


```{r, include=FALSE}
# Getting the counts of positive and negative words
bing_word_counts <- tidy_book %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts
```


```{r fig.width=6, fig.height=2,fig.cap="negative and positive words count"}
# Plotting the frequency of positive and negative words in book respectively
library(ggplot2)
bing_word_counts %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)
```


I also got word cloud figures, figure 4 shows the frequency of words appeared in book, the two main characters' name is the bigest part of figure. And figure 5 is about sentimental words, which are separate into positive side and negative side.

```{r fig.cap="word cloud"}
#install.packages("wordcloud")
library(wordcloud)
# Plotting word cloud of words in book
tidy_book %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100,ramdom.order = T,colors = c("#3e236e", "#673AB7", "#9370d2", 
                               "#0044a9", "#1B76FF", "#76adff", 
                               "#28602b", "#43A047", "#87cd8a")))
```

```{r fig.cap="sentiment word cloud"}
library(reshape2)
# Plotting word cloud of sentimental words in book including negative side and positive side
tidy_book %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)
```

## Extra credit of Task two

I found another lexicon provided in package  'textdata' called 'Loughran-Mcdonald', when I used this new lexicon to get similar figure and result as before.
```{r}
# Using the new lexicon to get sentiment score
new<-tidy_book %>% 
    inner_join(get_sentiments("loughran")) %>%
    mutate(method = "Loughran-McDonald")  %>% 
  count(method, index = linenumber %/% 80, sentiment) %>% 
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
# Getting the new barplot
new%>%ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +labs(title='Loughran-McDonald')+
  theme_bw()+theme(plot.title = element_text(hjust = 0.5))
```



## Task three
```{r}
#write.table(data,'Garden.txt',row.names = F) 
#garden <- read.table('Garden.txt',header = TRUE)
```

```{r}
#tnBooksFromLines(garden$text, "Burnett/Garden")
```

```{r}
# Changing my book into tnum
#write.table(data,'Fox.txt',row.names = F) 
fox <- read.table('Fox.txt',header = TRUE)
#tnBooksFromLines(fox$text, "Burgess/Fox")
```





```{r}
# Create tidy book
tidy_fox <- fox %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, 
                                regex("chapter", 
                                      ignore_case = TRUE)))) %>% 
  unnest_tokens(word, text) 
```

First of all, I change my book into tnum form, and the content of my tnum database is shown as follow:



Secondly I use sentimentr to get sentiment score group by these scores with section to get the average result. The plot sort the average sentiment score from high to low.
```{r}
# Separate into different columns
query<- tnum.query('Burgess/fox/section# has text',max=5000) %>% tnum.objectsToDf()
query %>% view()
fox_sentence<-query %>% separate(col=subject,
                  into = c("path1", "path2","section","paragraph","sentence"), 
                  sep = "/", 
                  fill = "right") %>% 
  select(section:string.value)
```

```{r}
# Get the number of section, paragraph and sentence
fox_sentence<-fox_sentence %>% 
  mutate_at(c('section','paragraph','sentence'),~str_extract_all(.,"\\d+") %>%
              unlist() %>%
              as.numeric())%>%
  filter(section !=0)
```


```{r}
# Use sentimentr to get sentiment score group by these scores with section to get the average result
library(magrittr)
sentence_out<-fox_sentence %>%
  filter(section !=0)%>% dplyr::mutate(sentence_split = get_sentences(string.value)) %$%
    sentiment_by(sentence_split, list(section))
  

plot(sentence_out)
```

### Compare the analysis result with Task two

Because the scale of scores of two methods are different, so I need to change them into one consistent scale using function, then I get the bar plot for two scores.


```{r}
# Create a new bing with index=chapter
new_bing<-tidy_fox %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al.") %>% 
    count(method, index = chapter, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)

# Scale sentiment to keep unit same 
new_bing2<-new_bing %>% 
  mutate(bing_scale=scale(sentiment)) %>% 
  select(method,index,bing_scale)

# Change the name of column two in order to join by section
colnames(new_bing2)[2]='section'

# Scale sentiment to keep unit same 
sentence_out<-sentence_out %>% mutate(sentimentr_scale=scale(ave_sentiment))

# Join two df
sentence_out_2method<-left_join(sentence_out,new_bing2,by='section')%>% select(section,bing_scale,sentimentr_scale)

# Use pivot longer for ggplot
sentence_out_2method_plot<-sentence_out_2method %>% pivot_longer(cols=c('sentimentr_scale','bing_scale'),names_to = 'sentiment')

# Create barplot to compare
sentence_out_2method_plot %>%ggplot(aes(y=value,x=factor(section))) +
  geom_bar(aes(fill=factor(sentiment)),stat='identity',position = "dodge",width = 0.7)+theme_bw()

```

## Extra credit of Task three: character analysis

As I said in Task two, there are two main characters in this book, one is Granny Fox and other is Reddy. So I select them from my book and count their appeared frequency in each chapter. seeing the table I found in most of the chapter Granny appears more than Reddy.

```{r}
# Find the two main characters Granny and Reddy
book_sentence_indi<-fox_sentence %>% mutate(granny=str_match(fox_sentence$string.value,regex('(Granny)'))[,1],
                         reddy=str_match(fox_sentence$string.value,regex('(Reddy)'))[,1])
# Use sentiment_by to get the score
score<-book_sentence_indi %>% dplyr::mutate(sentence_split = get_sentences(string.value))%$%
    sentiment_by(sentence_split) %>% `$`(ave_sentiment)
# Count two characters' time in each chapter
book_sentence_indi$score<-score
re<-book_sentence_indi %>% group_by(section) %>% summarise(granny=sum(granny %>% is.na() %>% `!`()),
                                                       reddy=sum(reddy%>% is.na() %>% `!`()))
knitr::kable(re,'simple')
# use group by to display the result
re2<-book_sentence_indi %>% group_by(section,paragraph) %>% summarise(
  both_appear=sum(granny %>% is.na() %>% `!`() & reddy%>% is.na() %>% `!`() ))
#re2 %>% filter(both_appear>0)
knitr::kable(re2 %>% filter(both_appear>0),'simple')
```
